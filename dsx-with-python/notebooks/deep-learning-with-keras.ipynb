{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python37764bit19b558fa8aff4326bd1b6482cc6b6618",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning and Neural Networks with Keras\n",
    "\n",
    "> Notes from [this YouTube Series](https://www.youtube.com/watch?v=zYnI4iWRmpc), Full course notes can be found on [GitHub](https://github.com/jeffheaton/t81_558_deep_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Neural Networks\n",
    "\n",
    "A Neural Network takes the some kind of data and has the ability to handle and process data that other ML models are not really able to process\n",
    "\n",
    "In a normal model you would pass in a 1D vector such as a list of predictors, with a an NN you can pass in more complex data and the model will place weight on the position as well as the values of a respective data point which is something other models can't necessarily handle\n",
    "\n",
    "Some examples of higher order data can be:\n",
    "\n",
    "1. 1D Vector - Normal input, like a row in a spreadsheet\n",
    "2. 2D Matrix - Grayscale image\n",
    "3. 3D Matrix - Colour image\n",
    "4. nD Matrix - Any higher order data\n",
    "\n",
    "With traditional models we speak about regression or classification. \n",
    "\n",
    "A regression network could have a single numerical output, or a classification network could have a set of potential binary outputs for each classes (like one-hot) or a probability of the result being each of the possible outputs\n",
    "\n",
    "Neural Networks are also capble of more complex outputs or even combinations of outputs\n",
    "\n",
    "In general an NN consists of an Input Layer which takes in the input data, a few hidden layers which proces the data, and an output layer which is our target outcome. Each layer passes a weighted data to each model\n",
    "\n",
    "There are usually these types of neurons:\n",
    "\n",
    "1. Input - get the input data\n",
    "2. Hidden - between input and output and abstract processing\n",
    "3. Output - the output that's calculated\n",
    "4. Context - hold state between calls to the network\n",
    "5. Bias Neurons - similar to a y-intercept, alow us to offset the data to a neurons\n",
    "\n",
    "\n",
    "Neural networks pass data to nodes using Activation functions, some common ones are:\n",
    "\n",
    "- Rectified Linear Unit (ReLU) - used for hidden layers\n",
    "- Softmax - output for classification\n",
    "- Linear - for regression\n",
    "\n",
    "The Bias Neuron along with a Weight allow us to move and scale our activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow and Keras\n",
    "\n",
    "TensorFlow is the low-level library for Neural Networks, and Keras is an API that sits on top of TF and allows you to interact with it at a higher level\n",
    "\n",
    "> The current version of TF requires Python 3.7, so just align with that\n",
    "\n",
    "TensorBoard is a way to visualize Neural Networks \n",
    "\n",
    "### Using Tensorflow Directly\n",
    "\n",
    "#### Simple Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tf.Tensor([[12.]], shape=(1, 1), dtype=float32)\n"
    },
    {
     "data": {
      "text/plain": "12.0"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "matrix2 = tf.constant([[2.], [2.]])\n",
    "\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "print(product)\n",
    "float(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Variables\n",
    "\n",
    "Variables can be created, used, and resasigned and recalculated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[-2. -1.]\n"
    }
   ],
   "source": [
    "x = tf.Variable([1., 2.])\n",
    "a = tf.constant([3., 3.])\n",
    "\n",
    "print(tf.subtract(x, a).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1. 3.]\n"
    }
   ],
   "source": [
    "x.assign([4., 6.])\n",
    "\n",
    "print(tf.subtract(x, a).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras with MPG Dataset\n",
    "\n",
    "Keras enables us to think about the Layers in an NN, we'll use the Miles Per Gallon dataset which uses the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "\n",
    "COLUMN_NAMES = [\n",
    "        'mpg', \n",
    "        'cylinders', \n",
    "        'displacement', \n",
    "        'horsepower', \n",
    "        'weight', \n",
    "        'acceleration', \n",
    "        'model year', \n",
    "        'origin', \n",
    "        'car name'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "df = pd.read_fwf(\n",
    "    DATA_URL, \n",
    "    names=COLUMN_NAMES,\n",
    "    na_values=['NA', '?']\n",
    ")\n",
    "\n",
    "# fill missing\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>cylinders</th>\n      <th>displacement</th>\n      <th>horsepower</th>\n      <th>weight</th>\n      <th>acceleration</th>\n      <th>model year</th>\n      <th>origin</th>\n      <th>car name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>307.0</td>\n      <td>130.0</td>\n      <td>3504.0</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>\"chevrolet chevelle malibu\"</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15.0</td>\n      <td>8</td>\n      <td>350.0</td>\n      <td>165.0</td>\n      <td>3693.0</td>\n      <td>11.5</td>\n      <td>70</td>\n      <td>1</td>\n      <td>\"buick skylark 320\"</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>318.0</td>\n      <td>150.0</td>\n      <td>3436.0</td>\n      <td>11.0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>\"plymouth satellite\"</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16.0</td>\n      <td>8</td>\n      <td>304.0</td>\n      <td>150.0</td>\n      <td>3433.0</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>\"amc rebel sst\"</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.0</td>\n      <td>8</td>\n      <td>302.0</td>\n      <td>140.0</td>\n      <td>3449.0</td>\n      <td>10.5</td>\n      <td>70</td>\n      <td>1</td>\n      <td>\"ford torino\"</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n0  18.0          8         307.0       130.0  3504.0          12.0   \n1  15.0          8         350.0       165.0  3693.0          11.5   \n2  18.0          8         318.0       150.0  3436.0          11.0   \n3  16.0          8         304.0       150.0  3433.0          12.0   \n4  17.0          8         302.0       140.0  3449.0          10.5   \n\n   model year  origin                     car name  \n0          70       1  \"chevrolet chevelle malibu\"  \n1          70       1          \"buick skylark 320\"  \n2          70       1         \"plymouth satellite\"  \n3          70       1              \"amc rebel sst\"  \n4          70       1                \"ford torino\"  "
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['mpg', 'car name'], axis=1).values\n",
    "y = df[['mpg']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Regression Model with Keras\n",
    "\n",
    "When building a Neural Network we take the following steps:\n",
    "\n",
    "1. Create a Sequential\n",
    "2. Define the Hidden Layers\n",
    "3. Define the Output Layer\n",
    "4. Compile and Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define Hidden Layers\n",
    "\n",
    "Define the first hiddel layer with the `input_dim` to be the shape of our input data set (`X` columns in this case)\n",
    "\n",
    "> A dense layer is one where each neuron is connected to the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(25, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define the Output Layer\n",
    "\n",
    "This is depends on the dimensionality of the output, similar to the input. For this case it is one dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compile and train the model\n",
    "\n",
    "We specify a `loss` function and an `optimizer` for the model, and then give it the `X` and `y` values to train on a well as how many `epoch`s we want it to train for\n",
    "\n",
    "For a Regression NN you usually use MSE as the loss\n",
    "\n",
    "> We can also make use of methods to increase the model's effectiveness and identifying the optimal number of epochh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2041a5ff688>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, y, verbose=0, epochs=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'MSE: 3.4881811444565303'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_pred, y))\n",
    "'MSE: ' + str(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Classification Model with Keras\n",
    "\n",
    "Building a Classification Model is much the same, however we need to ensure that we hot-encode our categorical values, and in this case we'll have a categorical output which means more than one potential result\n",
    "\n",
    "For this we're making use of the [Iris Dataset](https://archive.ics.uci.edu/ml/datasets/Iris)\n",
    "\n",
    "However for a Multi-Class classification we use `softmax` and `categorical_crossentropy`\n",
    "\n",
    "For a Binary we can additionally use an appliccable loss and activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "\n",
    "COLUMN_NAMES = [\n",
    "   'sepal length',\n",
    "   'sepal width',\n",
    "   'petal length',\n",
    "   'petal width',\n",
    "   'class'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_URL, names=COLUMN_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length</th>\n      <th>sepal width</th>\n      <th>petal length</th>\n      <th>petal width</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   sepal length  sepal width  petal length  petal width        class\n0           5.1          3.5           1.4          0.2  Iris-setosa\n1           4.9          3.0           1.4          0.2  Iris-setosa\n2           4.7          3.2           1.3          0.2  Iris-setosa\n3           4.6          3.1           1.5          0.2  Iris-setosa\n4           5.0          3.6           1.4          0.2  Iris-setosa"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1).values\n",
    "dummies = pd.get_dummies(df['class'])\n",
    "\n",
    "species = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2041b8c9c88>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X, y, verbose=0, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1\n 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\nExpected: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\nIndex(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n       'Iris-setosa'],\n      dtype='object')\n"
    },
    {
     "data": {
      "text/plain": "'Accuracy: 0.9733333333333334'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "predict_classes = np.argmax(y_pred,axis=1)\n",
    "expected_classes = np.argmax(y,axis=1)\n",
    "print(f\"Predictions: {predict_classes}\")\n",
    "print(f\"Expected: {expected_classes}\")\n",
    "\n",
    "print(species[predict_classes[1:10]])\n",
    "\n",
    "score = metrics.accuracy_score(expected_classes,predict_classes)\n",
    "'Accuracy: ' + str(score)"
   ]
  }
 ]
}